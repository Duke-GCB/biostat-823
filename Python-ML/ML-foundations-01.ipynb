{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for practicing data scientists\n",
    "\n",
    "I will assume that most (all?) have taken or are concurrently taking a class (or classes) that focus  on the mathematics and algorithms behind ML. Here we focus mostly on practical aspects of ML (which also tend to be glossed over in more academic courses, but are nonetheless useful for a practicing data scientist).\n",
    "\n",
    "### Acknowledgments & Credits\n",
    "\n",
    "This lesson is adapted from the excellent curriculum materials by Cliburn Chan (2021) at https://github.com/cliburn/bios-823-2021/ under the MIT License.\n",
    "\n",
    "-----\n",
    "\n",
    "## Understanding ML\n",
    "\n",
    "- Model is learned from data, rather than pre-specified\n",
    "    * No explicit instructions\n",
    "    * No expert-constructed rules\n",
    "- Algorithms that get better at performing a task by learning from data\n",
    "\n",
    "### Learning modalities\n",
    "\n",
    "#### Labeled vs unlabeled data\n",
    "\n",
    "- Labeled data $\\to$ supervised learning\n",
    "- Unlabeled data $\\to$ unsupervised learning\n",
    "    * Could also be self-supervised learning\n",
    "- Future reward $\\to$ reinforcement learning\n",
    "\n",
    "#### Structured vs unstructured data\n",
    "\n",
    "- Structured data $\\to$ tabular data\n",
    "- Unstructured data just means non-tabular:\n",
    "    * free text\n",
    "    * images, video, audio\n",
    "    * sequences (e.g., time series)\n",
    "    * molecular sequences\n",
    "- In the past, unstructured data was first converted to structured data by *feature engineering*; this  has been upended by deep learning methods\n",
    "\n",
    "-----\n",
    "\n",
    "### ML model examples\n",
    "\n",
    "#### Supervised learning models\n",
    "\n",
    "##### Nearest neighbor\n",
    "[![KNN visualization](https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1531424125/KNN_final_a1mrv9.png)](https://medium.com/analytics-vidhya/different-types-of-machine-learning-algorithm-b4f76b5730fd)\n",
    "\n",
    "##### Linear models\n",
    "[![Polynomial regression visual](https://static.javatpoint.com/tutorial/machine-learning/images/machine-learning-polynomial-regression.png)](https://shishirkant.com/polynomial-regression-for-python/)\n",
    "\n",
    "##### Support vector machines\n",
    "[![SVM boundary visualization](https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/SVM_margin.png/300px-SVM_margin.png)](https://en.wikipedia.org/wiki/Support_vector_machine)\n",
    "\n",
    "##### Trees\n",
    "[![Visualization of Decision Tree](https://i1.wp.com/cdn-images-1.medium.com/max/1024/0*sE2yI-WvzJKNhdme.png?ssl=1&w=1600&resize=1600&ssl=1)](https://towardsai.net/p/programming/decision-trees-explained-with-a-practical-example-fe47872d3b53)\n",
    "\n",
    "##### Neural networks\n",
    "[![Neural Network visualization](https://ml-cheatsheet.readthedocs.io/en/latest/_images/dynamic_resizing_neural_network_4_obs.png)](https://ml-cheatsheet.readthedocs.io/en/latest/nn_concepts.html)\n",
    "\n",
    "##### Deep Neural Networks\n",
    "[![Deep Neural Network visualization](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UnHS6UvgzgFtBqVxcITHcQ.png)](https://medium.com/@anushkamittal/an-introduction-to-neural-networks-8f2cd1280ca9)\n",
    "\n",
    "-----\n",
    "\n",
    "## ML stages\n",
    "\n",
    "[![Machine learning lifecycle](https://images.javatpoint.com/tutorial/machine-learning/images/machine-learning-life-cycle.png)](https://www.javatpoint.com/machine-learning-life-cycle)\n",
    "\n",
    "### Data processing\n",
    "\n",
    "We typically need to process the data for it to work with a broad class of ML models. For example:\n",
    "- Categorical features need to be encoded as numbers\n",
    "- Sequences of categorical features need to be encoded as vectors\n",
    "- Unstructured data columns (natural language text etc) need to be encoded as vectors\n",
    "- Missing data needs may need to be imputed\n",
    "- Large variations in measurement scales need to be standardized\n",
    "\n",
    "**Note:** To avoid data *leakage*, any preprocessing that has a *fit* stage should estimate parameters on *training* data only.\n",
    "\n",
    "#### Category encoding\n",
    "\n",
    "- Encoding without labels\n",
    "- Encoding with labels\n",
    "- Numeric encoding\n",
    "- One-hot encoding\n",
    "\n",
    "#### Feature selection\n",
    "\n",
    "- Uninformative variables\n",
    "- Collinear or multi-collinear variables\n",
    "- Dependent features\n",
    "- Recursive feature elimination\n",
    "\n",
    "In deep learning, feature selection is often done implicitly by the model during training. However, this requires regularization to prevent overfitting, and to incentivize the model to drop or downweight uninformative features.\n",
    "\n",
    "#### Shuffling \n",
    "\n",
    "- Shuffling breaks up any order to the observations\n",
    "- This is important for cross-validation and for stochastic gradient descent. If you haven't shown that there isn't an order to the data, assume that there is.\n",
    "\n",
    "#### Standardization\n",
    "\n",
    "- Distance-based models may be sensitive to scale\n",
    "- Convert features to have zero mean and unit standard deviation\n",
    "\n",
    "-----\n",
    "\n",
    "### Model training\n",
    "\n",
    "#### Memorization and generalization: The bias-variance trade-off\n",
    "\n",
    "- The entire point of any form of learning is generalization, not memorization\n",
    "- Model capacity is the amount of information a model can store\n",
    "- If model capacity $\\gg$ data complexity, the model will perform best by just memorizing the data $\\to$ over-fitting\n",
    "- If model capacity $\\ll$ data complexity, the model will not be very good $\\to$ under-fitting\n",
    "\n",
    "[![Bias-vs-variance tradeoff visualization](figs/Bias-vs-Variance-tradeoff.jpg)](https://stats.stackexchange.com/questions/543509/why-test-error-and-variance-has-different-curve-in-bias-variance-trade-off-graph)\n",
    "\n",
    "[![img](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3flBvsYv8dsRqX4ruYdjew.png)](https://medium.com/@cristianefragata/machine-learning-bias-and-variance-26b6ee572af)\n",
    "\n",
    "#### Tracking training and validation measures\n",
    "\n",
    "[![Visualization of training and test loss over epochs](https://www.baeldung.com/wp-content/uploads/sites/4/2021/11/epoch-training-curve.png)](https://www.baeldung.com/cs/ml-underfitting-overfitting)\n",
    "\n",
    "#### Remedies for over-fitting\n",
    "\n",
    "- Synthetic data and data augmentation\n",
    "- Pre-training\n",
    "- Early stopping\n",
    "- L1 and L2 regularization\n",
    "- Model-specific parameters for controlling model complexity\n",
    "- Dropout\n",
    "\n",
    "#### Remedies for under-fitting\n",
    "\n",
    "- Collect more data\n",
    "- Increase model complexity\n",
    "- Decrease regularization\n",
    "- Change learning rate\n",
    "\n",
    "#### Data leakage\n",
    "\n",
    "- Data leakage is using information in the model training process that would not be expected to be available at prediction time.\n",
    "    * When evaluating model performance on held-out test data, if data leakage occurred, some information about the test data has been \"leaked\" to the model training, making the test data not truly unseen data.\n",
    "    * Causes the predictive scores (metrics) to overestimate the model's performance.\n",
    "    * Can also result in choosing an inferior model, or suboptimal hyperparameters.\n",
    "\n",
    "[![Fig. 1: Visualization of the lifecycle of an ML model f. From: Bernett et al. Guiding questions to avoid data leakage in biological machine learning applications. Nat Methods 21, 1444–1453 (2024)](figs/41592_2024_2362_Fig1_HTML.png)](https://www.nature.com/articles/s41592-024-02362-y/figures/1)\n",
    "\n",
    "- Data leakage can be quite subtle and can occur in many ways:\n",
    "    * Feature leakage: Including a feature in training that \"leaks\" information about the target variable (but wouldn't be available at prediction time)\n",
    "    * Row-wise leakage:\n",
    "        + Duplication of rows or items between training and test data.\n",
    "        + Data pre-processing that uses information from the test set. For example, standardizing or normalizing the data _before_ splitting the data.\n",
    "        + Groups of related rows (e.g., same patient, same gene, etc) that end up in both training and test data.\n",
    "- Importance of using reproducible workflow\n",
    "\n",
    "Data leakage has been identified as a major issue in ML reproducibility. For example, Kapoor and Narayanan (2023) identify data leakage as the most common cause of the reproducibility crisis in ML-based science:\n",
    "> [...] We also tested the reproducibility of ML in a specific field: predicting civil wars, where complex ML models were thought to outperform traditional statistical models. Interestingly, when we corrected for data leakage, the supposed superiority of ML models disappeared: they did not perform any better than older methods. [...]\n",
    ">\n",
    "> Kapoor S, Narayanan A. [Leakage and the reproducibility crisis in machine-learning-based science.](https://doi.org/10.1016/j.patter.2023.100804) Patterns (N Y). 2023 Aug 4;4(9):100804. PMID: 37720327; PMCID: PMC10499856.\n",
    "\n",
    "[![Fig. 2: Schematic overview of the seven questions designed to reveal data leakage. From: Bernett et al. Guiding questions to avoid data leakage in biological machine learning applications. Nat Methods 21, 1444–1453 (2024)](figs/41592_2024_2362_Fig2_HTML.png)](https://www.nature.com/articles/s41592-024-02362-y/figures/2)\n",
    "\n",
    "Fig. 2: Schematic overview of the seven questions designed to reveal data leakage. From:\n",
    "> Bernett, J., Blumenthal, D.B., Grimm, D.G. et al. [Guiding questions to avoid data leakage in biological machine learning applications.](https://doi.org/10.1038/s41592-024-02362-y) Nat Methods 21, 1444–1453 (2024).\n",
    "\n",
    "#### Imbalanced data\n",
    "\n",
    "- Choice of evaluation metrics (e.g. [Kappa](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.cohen_kappa_score.html))\n",
    "- Weighting samples\n",
    "- Majority under-sampling\n",
    "- Minority over-sampling\n",
    "\n",
    "#### Hyper-parameter tuning\n",
    "\n",
    "- Role of cross-validation\n",
    "- Grid search\n",
    "- Auto-tuning\n",
    "\n",
    "-----\n",
    "\n",
    "### Model evaluation\n",
    "\n",
    "#### Unsupervised learning metrics\n",
    "\n",
    "##### Dimension reduction\n",
    "\n",
    "- Principal Component Analysis (PCA)\n",
    "    - Explained variance\n",
    "    - Scree plot\n",
    "    - Loadings\n",
    "    - Biplots\n",
    "- t-Distributed Stochastic Neighbor Embedding ([t-SNE](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding))\n",
    "- Uniform manifold approximation and projection ([UMAP](https://umap-learn.readthedocs.io/en/latest/))\n",
    "\n",
    "Breast cancer data visualized with PCA, t-SNE, and UMAP:\n",
    "![Plots contrasting PCA, t-SNE, and UMAP](figs/PCA-tSNE-UMAP.png)\n",
    "\n",
    "[MNIST](https://en.wikipedia.org/wiki/MNIST_database) data visualized with t-SNE:\n",
    "[![t-SNE visualization of MNIST data](https://upload.wikimedia.org/wikipedia/commons/f/f1/T-SNE_Embedding_of_MNIST.png)](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding)\n",
    "\n",
    "##### Information criteria for probabilistic models\n",
    "\n",
    "- Negative log likelihood and deviance\n",
    "- AIC\n",
    "- BIC\n",
    "\n",
    "#### Supervised learning metrics\n",
    "\n",
    "##### Classification metrics\n",
    "\n",
    "- Confusion matrix and binary scores\n",
    "- ROC curve\n",
    "- PR curve\n",
    "- Cumulative gains curve\n",
    "- Discrimination threshold\n",
    "\n",
    "##### Regression metrics\n",
    "\n",
    "- Residual plot\n",
    "- Prediction error plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
